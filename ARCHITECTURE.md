# üèóÔ∏è System Architecture Documentation

This document provides a detailed technical overview of the Neuropathology Detection System architecture.

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture Layers](#architecture-layers)
3. [Component Details](#component-details)
4. [Data Flow](#data-flow)
5. [Model Architecture](#model-architecture)
6. [Training Pipeline](#training-pipeline)
7. [Inference Pipeline](#inference-pipeline)
8. [Design Decisions](#design-decisions)

## System Overview

The system is built with a modular, layered architecture following software engineering best practices:

- **Separation of Concerns**: Each module has a single responsibility
- **Modularity**: Components can be replaced or upgraded independently
- **Extensibility**: Easy to add new models, features, or visualizations
- **Maintainability**: Clear code structure with comprehensive documentation

### Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Frontend | Streamlit | Web UI and user interaction |
| Backend | Python | Application logic |
| ML Framework | TensorFlow/Keras | Deep learning model |
| Data Processing | NumPy, Pillow, OpenCV | Image preprocessing |
| Visualization | Matplotlib, Plotly, Seaborn | Charts and plots |
| Deployment | (Configurable) | Docker, Cloud platforms |

## Architecture Layers

### 1. Presentation Layer (UI)

**File**: `app.py`

**Responsibilities**:
- User interface rendering
- Input handling (image uploads)
- Result visualization
- Educational content presentation

**Components**:
- Home page with project overview
- Detection page with image upload
- Model information page
- Theory/documentation pages

**Technologies**: Streamlit, Plotly, HTML/CSS

### 2. Application Layer

**Files**: `train.py`, `demo.py`

**Responsibilities**:
- Training orchestration
- Model evaluation
- Demo/testing utilities
- CLI interfaces

**Components**:
- Training script with argument parsing
- Demo script for testing
- Validation script for CI/CD

### 3. Model Layer

**Directory**: `src/models/`

**Responsibilities**:
- Neural network architecture definition
- Model compilation and configuration
- Training callbacks
- Prediction interface

**Key Classes**:
- `NeuropathologyModel`: Main model wrapper
  - `build_model()`: Constructs architecture
  - `compile_model()`: Configures optimizer and loss
  - `fine_tune_model()`: Enables fine-tuning
  - `predict()`: Makes predictions

**Supported Architectures**:
1. EfficientNetB0 (default)
2. ResNet50
3. VGG16
4. MobileNetV2

### 4. Data Layer

**Directory**: `src/data/`

**Responsibilities**:
- Image loading and preprocessing
- Data augmentation
- Batch generation
- Dataset management

**Key Classes**:
- `MRIDataLoader`: Image preprocessing
  - `load_and_preprocess_image()`: Single image
  - `load_batch()`: Batch processing
  - `augment_image()`: Data augmentation

- `DataGenerator`: Training data generator
  - Inherits from `tf.keras.utils.Sequence`
  - On-the-fly loading for memory efficiency
  - Automatic shuffling and batching

### 5. Utility Layer

**Directory**: `src/utils/`

**Responsibilities**:
- Visualization utilities
- Model evaluation
- Helper functions
- Constants and configurations

**Key Classes**:
- `Visualizer`: Plotting utilities
  - Training history plots
  - Confusion matrices
  - Prediction confidence charts

- `ModelEvaluator`: Evaluation metrics
  - Accuracy, precision, recall, F1
  - Confusion matrix computation
  - Classification reports

## Component Details

### NeuropathologyModel Class

```python
class NeuropathologyModel:
    """
    Main model wrapper that encapsulates:
    - Base model selection and loading
    - Custom classification head
    - Two-stage training support
    - Prediction interface
    """
```

**Architecture Flow**:

```
Input (224, 224, 3)
    ‚Üì
Base Model (Pre-trained)
    ‚Üì
Global Average Pooling
    ‚Üì
Batch Normalization
    ‚Üì
Dense(512) + ReLU
    ‚Üì
Dropout(0.5)
    ‚Üì
Dense(256) + ReLU
    ‚Üì
Batch Normalization
    ‚Üì
Dropout(0.3)
    ‚Üì
Dense(4) + Softmax
    ‚Üì
Output (4 class probabilities)
```

**Design Rationale**:

1. **Pre-trained Base**: Leverages ImageNet knowledge
2. **Global Average Pooling**: Reduces parameters, spatial invariance
3. **Batch Normalization**: Stabilizes training, faster convergence
4. **Dense Layers**: Learn classification from extracted features
5. **Dropout**: Prevents overfitting, improves generalization
6. **Softmax Output**: Probability distribution over classes

### Data Processing Pipeline

```
Raw MRI Image
    ‚Üì
Load Image (PIL)
    ‚Üì
Resize to 224√ó224 (bilinear interpolation)
    ‚Üì
Convert to NumPy array
    ‚Üì
Normalize to [0, 1]
    ‚Üì
[Optional] Data Augmentation
    ‚Üì
Batch Assembly
    ‚Üì
Model Input
```

**Data Augmentation** (Training only):
- Random rotation: ¬±20¬∞
- Random zoom: ¬±10%
- Horizontal flip: 50% probability

**Mathematical Operations**:
- Normalization: `x_norm = x / 255.0`
- Rotation: Apply affine transformation matrix
- Zoom: Scale coordinates by random factor
- Flip: Mirror image across vertical axis

## Data Flow

### Training Flow

```
Dataset Directory
    ‚Üì
[Load image paths and labels]
    ‚Üì
[Train/Val/Test split]
    ‚Üì
DataGenerator (with augmentation)
    ‚Üì
Model.fit()
    ‚îú‚îÄ‚Üí Forward pass
    ‚îú‚îÄ‚Üí Loss calculation
    ‚îú‚îÄ‚Üí Backpropagation
    ‚îú‚îÄ‚Üí Weight update
    ‚îî‚îÄ‚Üí Validation
    ‚Üì
[Callbacks]
    ‚îú‚îÄ‚Üí ModelCheckpoint (save best)
    ‚îú‚îÄ‚Üí EarlyStopping (prevent overfit)
    ‚îú‚îÄ‚Üí ReduceLROnPlateau (adaptive LR)
    ‚îî‚îÄ‚Üí TensorBoard (logging)
    ‚Üì
Trained Model
```

### Inference Flow

```
User Upload (Web UI)
    ‚Üì
Temporary Save
    ‚Üì
MRIDataLoader.load_and_preprocess_image()
    ‚îú‚îÄ‚Üí Resize
    ‚îú‚îÄ‚Üí Normalize
    ‚îî‚îÄ‚Üí Format
    ‚Üì
np.expand_dims() [Add batch dimension]
    ‚Üì
Model.predict()
    ‚îú‚îÄ‚Üí Forward pass only
    ‚îú‚îÄ‚Üí No gradient computation
    ‚îî‚îÄ‚Üí No dropout
    ‚Üì
Softmax Probabilities
    ‚îú‚îÄ‚Üí Class predictions
    ‚îú‚îÄ‚Üí Confidence scores
    ‚îî‚îÄ‚Üí All class probabilities
    ‚Üì
Visualization
    ‚îú‚îÄ‚Üí Bar chart
    ‚îú‚îÄ‚Üí Class description
    ‚îî‚îÄ‚Üí Warning if low confidence
    ‚Üì
Display to User
```

## Model Architecture

### Base Models Comparison

| Model | Parameters | Size | Speed | Accuracy | Best For |
|-------|-----------|------|-------|----------|----------|
| EfficientNetB0 | ~5.3M | 21 MB | Medium | Highest | **Production** (recommended) |
| ResNet50 | ~25.6M | 98 MB | Medium | High | High accuracy needs |
| VGG16 | ~138M | 528 MB | Slow | Good | Learning/baseline |
| MobileNetV2 | ~3.5M | 14 MB | Fast | Good | **Mobile/Edge devices** |

### Classification Head Design

```python
# Feature extraction from base model
# Output shape: (batch, 7, 7, channels)

GlobalAveragePooling2D()
# Output: (batch, channels)
# Reduces spatial dimensions dramatically

BatchNormalization()
# Normalizes features
# Stabilizes training

Dense(512, activation='relu')
# First fully connected layer
# Learns feature combinations

Dropout(0.5)
# Prevents overfitting
# 50% dropout rate

Dense(256, activation='relu')
# Second fully connected layer
# Additional learning capacity

BatchNormalization()
# Second normalization

Dropout(0.3)
# Lower dropout for deeper layer

Dense(4, activation='softmax')
# Output layer
# 4 class probabilities
```

**Total Parameters (EfficientNetB0)**:
- Base model: ~5.3M parameters
- Classification head: ~2.1M parameters
- **Total**: ~7.4M parameters

## Training Pipeline

### Two-Stage Training Strategy

#### Stage 1: Feature Extraction (20-30 epochs)

**Configuration**:
```python
base_model.trainable = False  # Freeze all base layers
learning_rate = 0.001
optimizer = Adam
batch_size = 32
epochs = 30
```

**Purpose**:
- Train only the new classification layers
- Learn task-specific features on top of general features
- Faster convergence (fewer parameters to update)

**Expected Progress**:
```
Epoch 1:  Loss: 1.20  Acc: 0.60
Epoch 10: Loss: 0.45  Acc: 0.83
Epoch 20: Loss: 0.28  Acc: 0.88
Epoch 30: Loss: 0.20  Acc: 0.91
```

#### Stage 2: Fine-Tuning (10-20 epochs)

**Configuration**:
```python
base_model.trainable = True
# Freeze first N layers, unfreeze last M layers
learning_rate = 0.0001  # Lower!
optimizer = Adam
batch_size = 32
epochs = 20
```

**Purpose**:
- Adapt pre-trained features to medical images
- Learn domain-specific low-level features
- Squeeze out final accuracy points

**Expected Progress**:
```
Epoch 1:  Loss: 0.18  Acc: 0.92
Epoch 10: Loss: 0.12  Acc: 0.95
Epoch 20: Loss: 0.10  Acc: 0.96
```

### Loss Function

**Categorical Cross-Entropy**:
```
L = -Œ£·µ¢ y·µ¢ log(≈∑·µ¢)

where:
- y·µ¢: true label (one-hot)
- ≈∑·µ¢: predicted probability
```

**Properties**:
- Convex (single global minimum)
- Differentiable (enables gradient descent)
- Penalizes confident wrong predictions heavily
- Perfect when ≈∑ = y (loss = 0)

### Optimization

**Adam Optimizer**:
```
Parameters:
- learning_rate: 0.001 (stage 1), 0.0001 (stage 2)
- beta1: 0.9 (momentum)
- beta2: 0.999 (adaptive learning rate)
- epsilon: 1e-8
```

**Why Adam?**:
- Adaptive per-parameter learning rates
- Momentum helps escape saddle points
- Works well with sparse gradients
- Robust to hyperparameter choices
- Industry standard for deep learning

### Callbacks

```python
ModelCheckpoint:
    monitor = 'val_accuracy'
    save_best_only = True
    # Keeps only best performing model

EarlyStopping:
    monitor = 'val_loss'
    patience = 10
    restore_best_weights = True
    # Stops if no improvement for 10 epochs

ReduceLROnPlateau:
    monitor = 'val_loss'
    factor = 0.5
    patience = 5
    # Halves LR if plateau for 5 epochs

TensorBoard:
    log_dir = 'logs'
    histogram_freq = 1
    # Logs metrics for visualization
```

## Inference Pipeline

### Prediction Steps

1. **Preprocessing**:
   ```python
   image = load_image(path)
   image = resize(image, (224, 224))
   image = normalize(image)  # [0, 1]
   image = expand_dims(image, 0)  # Add batch dimension
   ```

2. **Forward Pass**:
   ```python
   predictions = model.predict(image)
   # No backprop, no gradient computation
   # Dropout layers disabled
   # Batch norm uses running statistics
   ```

3. **Post-processing**:
   ```python
   class_idx = argmax(predictions)
   confidence = max(predictions)
   all_probs = predictions[0]
   ```

4. **Visualization**:
   - Bar chart of all class probabilities
   - Highlighted predicted class
   - Confidence threshold checking
   - Class description display

## Design Decisions

### 1. Why Transfer Learning?

**Problem**: Training from scratch requires:
- Millions of labeled images
- Weeks of training time
- Massive computational resources

**Solution**: Transfer learning
- Pre-trained on ImageNet (1.2M images)
- General features transfer to medical images
- Faster convergence, better accuracy

### 2. Why Two-Stage Training?

**Alternative**: Train everything together

**Our Approach**: Two stages
1. First train new layers
2. Then fine-tune base model

**Benefits**:
- New layers stabilize first
- Prevents destroying pre-trained weights
- Better final accuracy
- More stable training

### 3. Why Multiple Model Options?

Different use cases need different models:
- **Research/Learning**: VGG16 (simple architecture)
- **Production**: EfficientNet (best accuracy/speed)
- **Mobile**: MobileNetV2 (smallest, fastest)
- **High Accuracy**: ResNet50 (deep network)

### 4. Why Global Average Pooling?

**Alternative**: Flatten layer

**Our Choice**: GAP
- Much fewer parameters (prevents overfitting)
- Spatial invariance (position doesn't matter)
- Better generalization
- Standard in modern architectures

### 5. Why Data Augmentation?

**Problem**: Limited medical image data

**Solution**: Augmentation
- Artificially increases dataset size
- Improves generalization
- Makes model robust to variations
- No cost (just transformations)

### 6. Why Batch Normalization?

**Benefits**:
- Normalizes activations between layers
- Allows higher learning rates
- Reduces internal covariate shift
- Acts as regularization
- Faster convergence

### 7. Why Dropout?

**Problem**: Overfitting on small datasets

**Solution**: Dropout
- Randomly deactivates neurons
- Forces redundant representations
- Prevents co-adaptation
- Simple and effective

## Performance Considerations

### Memory Usage

**Training**:
- Model: ~500 MB (GPU memory)
- Batch (32 images): ~200 MB
- Gradients: ~500 MB
- **Total**: ~1.2 GB GPU memory minimum

**Inference**:
- Model: ~500 MB
- Single image: ~6 MB
- **Total**: ~512 MB

### Speed Benchmarks

**Training** (EfficientNetB0, RTX 3090):
- Batch (32 images): ~0.5 seconds
- Epoch (~1000 images): ~15 seconds
- Full training (50 epochs): ~12 minutes

**Inference** (CPU):
- Single image: ~200 ms
- Batch (32 images): ~2 seconds

**Inference** (GPU):
- Single image: ~50 ms
- Batch (32 images): ~200 ms

### Optimization Tips

**For Training**:
1. Use GPU (10-20x faster)
2. Larger batch size (better GPU utilization)
3. Mixed precision training (2x faster)
4. Use MobileNet for quick experiments

**For Inference**:
1. Batch predictions when possible
2. Use TensorFlow Lite for mobile
3. Quantization for edge devices
4. Model pruning for smaller size

## Extensibility

### Adding New Models

```python
# In src/models/neuropathology_model.py
def _get_base_model(self):
    if self.base_model_name == 'new_model':
        base_model = NewModel(
            include_top=False,
            weights='imagenet',
            input_shape=self.input_shape
        )
    # ...
```

### Adding New Features

1. **Grad-CAM Visualization**:
   - Add to `Visualizer` class
   - Shows which regions influence predictions

2. **Ensemble Models**:
   - Create `EnsembleModel` class
   - Combine multiple architectures

3. **Active Learning**:
   - Add uncertainty estimation
   - Prioritize uncertain samples for labeling

### Deployment Options

1. **Docker Container**:
   ```dockerfile
   FROM tensorflow/tensorflow:latest
   COPY . /app
   RUN pip install -r requirements.txt
   CMD ["streamlit", "run", "app.py"]
   ```

2. **Cloud Platforms**:
   - AWS SageMaker
   - Google Cloud AI Platform
   - Azure ML

3. **Mobile/Edge**:
   - Convert to TensorFlow Lite
   - Optimize with quantization
   - Deploy on mobile devices

## Conclusion

This architecture provides:
- **Modularity**: Easy to modify and extend
- **Scalability**: Can handle large datasets
- **Performance**: Fast training and inference
- **Maintainability**: Clear code structure
- **Educational Value**: Well-documented for learning

The design balances simplicity with power, making it suitable for both learning and production use.
